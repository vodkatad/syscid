include: "snakemake"

rule eid_info:
    output: "eid_info"
    params: url=EID_META
    shell: "wget -O {output} {params.url}"

# columns:
#EID GROUP   COLOR   MNEMONIC    STD_NAME    EDACC_NAME  ANATOMY TYPE    AGE SEX SOLID_LIQUID    ETHNICITY   SINGLEDONOR_COMPOSITE
#
rule all_eids:
    input: expand("{look}_eids", look=CLASSES)

rule eids:
    input: "eid_info"
    output: "{look}_eids"
    run:
        if wildcards.look == 'wanted':
            lookfor = WANTED
        else:
            lookfor = CONTROLS
        with open(output[0], "w") as out:
            with open(input[0], 'r') as info:
                for l in info.readlines():
                    l = l.rstrip()
                    fields = l.split("\t")
                    if fields[3] in lookfor:
                        out.write(fields[0]+'\n')

# these are not specific enough and make a big mess
rule all_peaks:
    input: expand("peaks_{mark}_{look}", mark=WANTED_MARKERS, look=CLASSES)

rule all_bigwigs:
    input: expand("bigwig_{mark}_wanted", mark=WANTED_MARKERS)

# Snakemake would prefer to store EIDS in variables and no files?
rule peaks:
    input: "{look}_eids"
    output: "{kind}_{mark}_{look}"
    run:
        import urllib.request
        import os.path
        #os.mkdir(wildcard.mark)
        shell('mkdir -p '+wildcards.kind)
        with open(output[0], 'w') as out:
            with open(input[0], 'r') as eids_f:
                for l in eids_f.readlines():
                    l = l.rstrip()
                    fields = l.split("\t")
                    eid = fields[0]
                    print("going for " + wildcards.kind + " " + wildcards.mark + " " + eid)
                    try:
                        if wildcards.kind == "peaks":
                            if not os.path.exists(wildcards.kind+'/'+wildcards.mark+'_'+wildcards.look+'_'+eid+'.gappedPeak.gz'):
                                url = BASE_URL_CONSOLIDATED_PEAKS+eid+'-'+wildcards.mark+'.gappedPeak.gz'
                                urllib.request.urlretrieve(url, wildcards.kind+'/'+wildcards.mark+'_'+wildcards.look+'_'+eid+'.gappedPeak.gz')
                            else:
                                print("peak already there")
                        elif wildcards.kind == "bigwig":
                            url = BASE_URL_CONSOLIDATED_BW_SIGNAL+eid+'-'+wildcards.mark+'.fc.signal.bigwig'
                            url2 = BASE_URL_CONSOLIDATED_BW_PVAL+eid+'-'+wildcards.mark+'.pval.signal.bigwig'
                            if not os.path.exists(wildcards.kind+'/'+wildcards.mark+'_'+wildcards.look+'_'+eid+'.fc.signal.bigwig'):
                                urllib.request.urlretrieve(url, wildcards.kind+'/'+wildcards.mark+'_'+wildcards.look+'_'+eid+'.fc.signal.bigwig')
                            else: 
                                print("bw fc already there")
                            if not os.path.exists(wildcards.kind+'/'+wildcards.mark+'_'+wildcards.look+'_'+eid+'.pval.signal.bigwig'):
                                urllib.request.urlretrieve(url2, wildcards.kind+'/'+wildcards.mark+'_'+wildcards.look+'_'+eid+'.pval.signal.bigwig')
                            else:
                                print("bw pval already there")
                    except: # HTTPError:
                        out.write('missed\t'+wildcards.mark+'_'+wildcards.look+'_'+eid+"\t"+url+'\n')
                out.write('#placeholder, should rethink this\n') 
                #https://github.com/leipzig/SandwichesWithSnakemake

## needs to check: if peaks_mark_look is not there we should remove peaks dir automatically (or change this rule to have its real output, I'm already metablabbing)
# manually downloaded the three last H3K4me1 bigwigs cause the python was stuck with connection timed out?

#1 chrom
#2 chromStart
#3 chromEnd
#4 name
#5 score
#6 strand
#7 thickStart
#8 thickEnd
#9 itemRgb
#10 blockCount
#11 blockSizes
#12 blockStarts
#13 signalValue
#14 pValue
#15 qValue

#
#[egrassi@gncomp3 roadmap]$ for f in  peaks/*.gz; do zcat $f | cut -f 1,2,3,13,15 | awk -F'\t' -v OFS='\t' -vF=$f '{print F, $0}'; done | gzip > summary_peaks.gz
#[egrassi@gncomp3 roadmap]$ zcat summary_peaks.gz | sed 's/\.gappedPeak\.gz//1; s/peaks\///1'  | tr "_" "\t"| /data/egrassi/bioinfotree/local/bin/translate -a <(cut -f 1,6 eid_info) 3  > summary_peaks_annot.gz
rule sum_peak:
    input: expand("peaks_{mark}_{look}", mark=WANTED_MARKERS, look=CLASSES)
    output: "summary_peaks_annot.gz"
    shell: 
      """
        for f in  peaks/*.gz; do zcat $f | cut -f 1,2,3,13,15 | awk -F'\t' -v OFS='\t' -vF=$f '{{print F, $0}}'; done \
        | sed 's/\.gappedPeak\.gz//1; s/peaks\///1'  | tr "_" "\t"| /data/egrassi/bioinfotree/local/bin/translate -a <(cut -f 1,4 eid_info) 3 | gzip > {output}
      """

rule peaks_info:
    input: "summary_peaks_annot.gz"
    output: "peak_info.html"
    params: SRC_DIR+"/plot_roadmap_peaks.Rmd"
    shell:
        """
        WD=`pwd`; \\
        Rscript -e \"require( 'rmarkdown' ); render('{params}', params=list(data='{input}', wd=\\"$WD\\"), output_file='{output}', output_dir=\\"$WD\\")\"
        """

# we merge peaks for the same group of cells

rule all_merged_lines:
    input: expand("{cells}_{mark}.merged.gappedPeaks.gz", cells=LINES, mark=WANTED_MARKERS)


def get_peaks(wildcards):
    list_eid = PAIRINGS[wildcards.cells]
    return ["peaks/"+wildcards.mark+"_wanted_"+eid+".gappedPeak.gz" for eid in list_eid]
    
rule merged_peaks:
    input: 
        get_peaks
    output: "{cells}_{mark}.merged.gappedPeaks.gz"
    shell:
        "zcat {input} | sort -k1,1 -k2,2n | bedtools merge -c 13,14,15 -o collapse,collapse,collapse -i - | gzip > {output}"

#[egrassi@gncomp3 roadmap]$ bedtools intersect -wa -v -a mono_H3K4me1.merged.gappedPeaks.gz -b <(zcat nk_H3K4me1.merged.gappedPeaks.gz th_H3K4me1.merged.gappedPeaks.gz)  > prova2
#[egrassi@gncomp3 roadmap]$ bedtools intersect -wa -v -a mono_H3K4me1.merged.gappedPeaks.gz -b <(zcat nk_H3K4me1.merged.gappedPeaks.gz th_H3K4me1.merged.gappedPeaks.gz)  > prova
#[egrassi@gncomp3 roadmap]$ 
#[egrassi@gncomp3 roadmap]$ diff prova prova2
#[egrassi@gncomp3 roadmap]$ wc -l prova
#24815 prova
#[egrassi@gncomp3 roadmap]$ zcat mono_H3K4me1.merged.gappedPeaks.gz | wc -l
#73920

# could also be done without the LOO manually created dictionary but globbing for things different than wildcards.cells XXX FIXME
def leave_one_out(wildcards):
    import glob
    res = []
    #res = wildcards.cells+"_"+wildcards.mark+"merged.gappedPeaks.gz" # first one is always our specific wanted cell line.
    # no, needs to return a named dictionary with a single element and then a list :( Hardcoding numbers in the rule right now?
    # or build the input there... but won't have right dependencies tree!
    for cell in LOO[wildcards.cells]:
        other = glob.glob("{}_{}.merged.gappedPeaks.gz".format(cell, wildcards.mark))
        assert len(other) == 1
        res.append(other[0])
    return res

rule all_specific:
    input: expand("{cells}_{mark}.specific.peaks.gz", cells=LINES, mark=WANTED_MARKERS)

rule specific_peaks:
    input:
        leave_one_out
    output: "{cells}_{mark}.specific.peaks.gz"
    shell: "bedtools intersect -v -a {wildcards.cells}_{wildcards.mark}.merged.gappedPeaks.gz -b <(zcat {input}) | gzip > {output}"

#zcat peaks/H3K4me1_*control*.gz | sort -k1,1 -k2,2n

rule all_control_peaks:
    input: expand("{mark}_control.all.gz", mark=WANTED_MARKERS)

def get_controls(wildcards):
    import glob
    return glob.glob("peaks/{}_control_*.gappedPeak.gz".format(wildcards.mark))

rule control_peaks:
    input: 
        get_controls
    output: "{mark}_control.all.gz"
    shell: "zcat {input} | sort -k1,1 -k2,2n | gzip > {output}"
    
rule all_more_specific:
    input: expand("{cells}_{mark}.more.specific.peaks.gz", cells=LINES, mark=WANTED_MARKERS)

rule more_specific_peaks:
    input: "{cells}_{mark}.specific.peaks.gz", "{mark}_control.all.gz"
    output: "{cells}_{mark}.more.specific.peaks.gz"
    shell: "bedtools intersect -v -a  {input[0]} -b {input[1]} | gzip > {output}"


#[egrassi@gncomp3 roadmap]$ grep -f wanted_eids eid_info  > ../../local/share/data/eid_info_colored_manually
rule session:
    input: info="../../local/share/data/eid_info_colored_manually", ph1="bigwig_H3K4me1_wanted", ph2="bigwig_H3K27ac_wanted"
    output: xml= "igv_session.xml"
    run:
        from lxml import etree
        import glob
        #root = etree.XML("""
        #<?xml version="1.0" encoding="UTF-8" standalone="no"?>
        #<Session genome="mm10" hasGeneTrack="true" hasSequenceTrack="true" locus="chr18:61103572-61133139">
        #""")
        #root = etree.XML("<Session genome=\"mm10\" hasGeneTrack=\"true\" hasSequenceTrack=\"true\" locus=\"chr18:61103572-61133139\">")
        base_url = "http://gncomp1.ich.techosp.it/tracks/ext/egrassi/roadmap/"
        root = etree.Element("Session", genome="hg19", locus="chr12:62995535-62998748")
        tree = etree.ElementTree(root)
        ress = etree.SubElement(root, "Resources")
        #height="3680" name="DataPanel" width="1903
        panel = etree.SubElement(root, "Panel", height="3680", name="DataPanel", width="1903")
        files = glob.glob("bigwig/*_wanted_*.pval.signal.bigwig")
        base_paths = [os.path.basename(f) for f in files]
        eids = [(x.split("_")[2]).split('.')[0] for x in base_paths]
        wigs = {}
        print(eids)
        with open(input.info, 'r') as info:
            for l in info.readlines():
                l = l.strip()
                values = l.split("\t") # eid group color mnemonic name
                if values[0] in eids:
                    wigs[values[0]] = (values[2], values[4])
        def hex_to_rgb(value):
            """Return '(red, green, blue)' for the color given as #rrggbb. 
            que viva stackoverflow https://stackoverflow.com/questions/214359/converting-hex-color-to-rgb-and-vice-versa"""
            value = value.lstrip('#')
            lv = len(value)
            return tuple(int(value[i:i + lv // 3], 16) for i in range(0, lv, lv // 3)]])

        for eid, info in sorted(wigs.items()):
            for mark in WANTED_MARKERS:
                url = base_url+mark+"_wanted_"+eid+".pval.signal.bigwig"
                name = mark + " in " + info[1]
                color = hex_to_rgb(info[0])
                # very stupid to give ligher colors to the second mark, should make ok for every starting color sooner or later
                # right now I use very dark manually defined colors (those by the roadmap were too similar)
                if mark == WANTED_MARKERS[1]:
                    color = [(c+128)%255 for c in color]
                color = ','.join([str(x) for x in color])
                etree.SubElement(ress, "Resource", path=url)
                # panel figlio di session (root), track e datarange figli suoi
                #<Track altColor="0,0,178" autoScale="false" clazz="org.broad.igv.track.DataSourceTrack" color="128,218,235" displayMode="COLLAPSED" featureVisibilityWindow="-1" fontSize="10" id="http://gncomp1.ich.techosp.it/tracks/tracksDB/SID100273-RID100273-TID24938882172715377-mm10-Elena_Grassi.bigWig" name="TRCN0000096374_Ino80_ut" normalize="false" renderer="BAR_CHART" sortable="true" visible="true" windowFunction="mean">
                #<DataRange baseline="0.0" drawBaseline="true" flipAxis="false" maximum="104.769554" minimum="0.0" type="LINEAR"/>
                track = etree.SubElement(panel, "Track", color=color, displayMode="COLLAPSED", id=url, name=name, renderer="BAR_CHART", showDataRange="true", visible="true", windowFunction="mean", normalize="false", featureVisibilityWindow="-1", autoScale="false")
                #etree.SubElement(track, "DataRange", baseline="0.0", drawBaseline="true", flipAxis="false", maximum="100", minimum="0.0", type="LINEAR")    
        tree.write(output.xml, pretty_print=True)

