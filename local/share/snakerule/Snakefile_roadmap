include: "snakemake"

rule eid_info:
    output: "eid_info"
    params: url=EID_META
    shell: "wget -O {output} {params.url}"

# columns:
#EID GROUP   COLOR   MNEMONIC    STD_NAME    EDACC_NAME  ANATOMY TYPE    AGE SEX SOLID_LIQUID    ETHNICITY   SINGLEDONOR_COMPOSITE
#
rule all_eids:
    input: expand("{look}_eids", look=CLASSES)

rule eids:
    input: "eid_info"
    output: "{look}_eids"
    run:
        if wildcards.look == 'wanted':
            lookfor = WANTED
        else:
            lookfor = CONTROLS
        with open(output[0], "w") as out:
            with open(input[0], 'r') as info:
                for l in info.readlines():
                    l = l.rstrip()
                    fields = l.split("\t")
                    if fields[3] in lookfor:
                        out.write(fields[0]+'\n')

# these are not specific enough and make a big mess
rule all_peaks:
    input: expand("peaks_{mark}_{look}", mark=WANTED_MARKERS, look=CLASSES)

rule all_bigwigs:
    input: expand("bigwig_{mark}_wanted", mark=WANTED_MARKERS)

# Snakemake would prefer to store EIDS in variables and no files?
rule peaks:
    input: "{look}_eids"
    output: "{kind}_{mark}_{look}"
    run:
        import urllib.request
        import os.path
        #os.mkdir(wildcard.mark)
        shell('mkdir -p '+wildcards.kind)
        with open(output[0], 'w') as out:
            with open(input[0], 'r') as eids_f:
                for l in eids_f.readlines():
                    l = l.rstrip()
                    fields = l.split("\t")
                    eid = fields[0]
                    print("going for " + wildcards.kind + " " + wildcards.mark + " " + eid)
                    try:
                        if wildcards.kind == "peaks":
                            if not os.path.exists(wildcards.kind+'/'+wildcards.mark+'_'+wildcards.look+'_'+eid+'.gappedPeak.gz'):
                                url = BASE_URL_CONSOLIDATED_PEAKS+eid+'-'+wildcards.mark+'.gappedPeak.gz'
                                urllib.request.urlretrieve(url, wildcards.kind+'/'+wildcards.mark+'_'+wildcards.look+'_'+eid+'.gappedPeak.gz')
                            else:
                                print("peak already there")
                        elif wildcards.kind == "bigwig":
                            url = BASE_URL_CONSOLIDATED_BW_SIGNAL+eid+'-'+wildcards.mark+'.fc.signal.bigwig'
                            url2 = BASE_URL_CONSOLIDATED_BW_PVAL+eid+'-'+wildcards.mark+'.pval.signal.bigwig'
                            if not os.path.exists(wildcards.kind+'/'+wildcards.mark+'_'+wildcards.look+'_'+eid+'.fc.signal.bigwig'):
                                urllib.request.urlretrieve(url, wildcards.kind+'/'+wildcards.mark+'_'+wildcards.look+'_'+eid+'.fc.signal.bigwig')
                            else: 
                                print("bw fc already there")
                            if not os.path.exists(wildcards.kind+'/'+wildcards.mark+'_'+wildcards.look+'_'+eid+'.pval.signal.bigwig'):
                                urllib.request.urlretrieve(url2, wildcards.kind+'/'+wildcards.mark+'_'+wildcards.look+'_'+eid+'.pval.signal.bigwig')
                            else:
                                print("bw pval already there")
                    except: # HTTPError:
                        out.write('missed\t'+wildcards.mark+'_'+wildcards.look+'_'+eid+"\t"+url+'\n')
                out.write('#placeholder, should rethink this\n') 
                #https://github.com/leipzig/SandwichesWithSnakemake

## needs to check: if peaks_mark_look is not there we should remove peaks dir automatically (or change this rule to have its real output, I'm already metablabbing)
# manually downloaded the three last H3K4me1 bigwigs cause the python was stuck with connection timed out?

#1 chrom
#2 chromStart
#3 chromEnd
#4 name
#5 score
#6 strand
#7 thickStart
#8 thickEnd
#9 itemRgb
#10 blockCount
#11 blockSizes
#12 blockStarts
#13 signalValue
#14 pValue
#15 qValue

#
#[egrassi@gncomp3 roadmap]$ for f in  peaks/*.gz; do zcat $f | cut -f 1,2,3,13,15 | awk -F'\t' -v OFS='\t' -vF=$f '{print F, $0}'; done | gzip > summary_peaks.gz
#[egrassi@gncomp3 roadmap]$ zcat summary_peaks.gz | sed 's/\.gappedPeak\.gz//1; s/peaks\///1'  | tr "_" "\t"| /data/egrassi/bioinfotree/local/bin/translate -a <(cut -f 1,6 eid_info) 3  > summary_peaks_annot.gz
rule sum_peak:
    input: expand("peaks_{mark}_{look}", mark=WANTED_MARKERS, look=CLASSES)
    output: "summary_peaks_annot.gz"
    shell: 
      """
        for f in  peaks/*.gz; do zcat $f | cut -f 1,2,3,13,15 | awk -F'\t' -v OFS='\t' -vF=$f '{{print F, $0}}'; done \
        | sed 's/\.gappedPeak\.gz//1; s/peaks\///1'  | tr "_" "\t"| /data/egrassi/bioinfotree/local/bin/translate -a <(cut -f 1,4 eid_info) 3 | gzip > {output}
      """

rule peaks_info:
    input: "summary_peaks_annot.gz"
    output: "peak_info.html"
    params: SRC_DIR+"/plot_roadmap_peaks.Rmd"
    shell:
        """
        WD=`pwd`; \\
        Rscript -e \"require( 'rmarkdown' ); render('{params}', params=list(data='{input}', wd=\\"$WD\\"), output_file='{output}', output_dir=\\"$WD\\")\"
        """

# we merge peaks for the same group of cells

rule all_merged_lines:
    input: expand("{cells}_{mark}.merged.gappedPeaks.gz", cells=LINES, mark=WANTED_MARKERS)


def get_peaks(wildcards):
    list_eid = PAIRINGS[wildcards.cells]
    return ["peaks/"+wildcards.mark+"_wanted_"+eid+".gappedPeak.gz" for eid in list_eid]
    
rule merged_peaks:
    input: 
        get_peaks
    output: "{cells}_{mark}.merged.gappedPeaks.gz"
    shell:
        "zcat {input} | sort -k1,1 -k2,2n | bedtools merge -c 13,14,15 -o collapse,collapse,collapse -i - | gzip > {output}"

#[egrassi@gncomp3 roadmap]$ bedtools intersect -wa -v -a mono_H3K4me1.merged.gappedPeaks.gz -b <(zcat nk_H3K4me1.merged.gappedPeaks.gz th_H3K4me1.merged.gappedPeaks.gz)  > prova2
#[egrassi@gncomp3 roadmap]$ bedtools intersect -wa -v -a mono_H3K4me1.merged.gappedPeaks.gz -b <(zcat nk_H3K4me1.merged.gappedPeaks.gz th_H3K4me1.merged.gappedPeaks.gz)  > prova
#[egrassi@gncomp3 roadmap]$ 
#[egrassi@gncomp3 roadmap]$ diff prova prova2
#[egrassi@gncomp3 roadmap]$ wc -l prova
#24815 prova
#[egrassi@gncomp3 roadmap]$ zcat mono_H3K4me1.merged.gappedPeaks.gz | wc -l
#73920

# could also be done without the LOO manually created dictionary but globbing for things different than wildcards.cells XXX FIXME
def leave_one_out(wildcards):
    import glob
    res = []
    #res = wildcards.cells+"_"+wildcards.mark+"merged.gappedPeaks.gz" # first one is always our specific wanted cell line.
    # no, needs to return a named dictionary with a single element and then a list :( Hardcoding numbers in the rule right now?
    # or build the input there... but won't have right dependencies tree!
    for cell in LOO[wildcards.cells]:
        other = glob.glob("{}_{}.merged.gappedPeaks.gz".format(cell, wildcards.mark))
        assert len(other) == 1
        res.append(other[0])
    return res

rule all_specific:
    input: expand("{cells}_{mark}.specific.peaks.gz", cells=LINES, mark=WANTED_MARKERS)

rule specific_peaks:
    input:
        leave_one_out
    output: "{cells}_{mark}.specific.peaks.gz"
    shell: "bedtools intersect -v -a {wildcards.cells}_{wildcards.mark}.merged.gappedPeaks.gz -b <(zcat {input}) | gzip > {output}"

#zcat peaks/H3K4me1_*control*.gz | sort -k1,1 -k2,2n

rule all_control_peaks:
    input: expand("{mark}_control.all.gz", mark=WANTED_MARKERS)

def get_controls(wildcards):
    import glob
    return glob.glob("peaks/{}_control_*.gappedPeak.gz".format(wildcards.mark))

rule control_peaks:
    input: 
        get_controls
    output: "{mark}_control.all.gz"
    shell: "zcat {input} | sort -k1,1 -k2,2n | gzip > {output}"
    
rule all_more_specific:
    input: expand("{cells}_{mark}.more.specific.peaks.gz", cells=LINES, mark=WANTED_MARKERS)

rule more_specific_peaks:
    input: "{cells}_{mark}.specific.peaks.gz", "{mark}_control.all.gz"
    output: "{cells}_{mark}.more.specific.peaks.gz"
    shell: "bedtools intersect -v -a  {input[0]} -b {input[1]} | gzip > {output}"
